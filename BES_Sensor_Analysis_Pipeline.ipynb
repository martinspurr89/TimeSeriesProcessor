{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitdashenvcondaafc3fd1ed224455ca3aee86bd709bff6",
   "display_name": "Python 3.7.6 64-bit ('DashEnv': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.common import EmptyDataError\n",
    "from tqdm.autonotebook import trange, tqdm\n",
    "\n",
    "import chart_studio.plotly as py\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline.offline\n",
    "import datetime\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pytz import timezone\n",
    "import humanize\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "import requests\n",
    "import io\n",
    "import warnings\n",
    "\n",
    "from collections import OrderedDict\n",
    "from PyPDF2 import PdfFileMerger, PdfFileReader, PdfFileWriter\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path, convert_from_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_df(filename, index = False):\n",
    "    try:\n",
    "        if index == False:\n",
    "            df = pd.read_csv(filename)\n",
    "        else:\n",
    "            df = pd.read_csv(filename, index_col=0)\n",
    "    except EmptyDataError:\n",
    "        df = pd.DataFrame()\n",
    "    return df\n",
    "\n",
    "def set_date(date_str, old_tz, dt_format = \"%d/%m/%Y %H:%M:%S\"):\n",
    "    date_formats = [\"%d/%m/%Y %H:%M:%S\", \"%Y-%m-%d %H:%M:%S\", \"%Y-%m-%d %H:%M:%S.%f\"]\n",
    "    if date_str == 'NaT':\n",
    "        return pd.NaT\n",
    "    else:\n",
    "        date_formats.append(dt_format)\n",
    "        for format in date_formats:\n",
    "            try:\n",
    "                datetime_set_naive = datetime.strptime(date_str, format)\n",
    "                break\n",
    "            except ValueError:\n",
    "                continue\n",
    "        try:\n",
    "            datetime_set_old = timezone(old_tz).localize(datetime_set_naive)\n",
    "            datetime_set_utc = datetime_set_old.astimezone(timezone('UTC'))\n",
    "        except UnboundLocalError:\n",
    "            print(\"Set dt_format in function call or date_formats\")\n",
    "            raise\n",
    "        return datetime_set_utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get latest data if older than refresh limit in info\n",
    "def refresh_data():\n",
    "    try:\n",
    "        with open(\"Temp/Data/info/info_setup.csv\") as file:\n",
    "            info = OrderedDict()\n",
    "            info['setup'] = import_df(file, index = True)\n",
    "            date_end = set_date(info['setup'].loc['date_end_utc','value'].replace('+00:00',''), \"UTC\")\n",
    "            diff = datetime.now(timezone('UTC')) - date_end\n",
    "\n",
    "            #if temp info file is older than 4 hours get data for the first time\n",
    "            if diff > timedelta(hours = int(info['setup'].loc['refresh_hours','value'])):\n",
    "                from Scripts import GetLatestData\n",
    "\n",
    "    except IOError: #if temp info file doesn't exist get data for the first time\n",
    "        from Scripts import GetLatestData\n",
    "\n",
    "def import_temp_data(collection, col_type, index_bool, data_folder = \"Temp/Data/\"):\n",
    "    if col_type == \"odict\":\n",
    "        col = OrderedDict()\n",
    "        for filename in os.listdir(data_folder + collection):\n",
    "            file_id = filename.replace(collection + '_', '').replace('.csv', '')\n",
    "            col[file_id] = import_df(data_folder + collection + \"/\" + filename, index = index_bool)\n",
    "    elif col_type == \"list\":\n",
    "        col = []\n",
    "        for filename in os.listdir(data_folder + collection):\n",
    "            col.append(import_df(data_folder + collection + \"/\" + filename, index = index_bool))\n",
    "    else:\n",
    "        col = \"\"\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create plotly chart figures\n",
    "def create_chart_fig(chart):\n",
    "    chart_fig = OrderedDict()\n",
    "    chart_info = info['plots'].loc[info['plots'].index == chart][info['plots'].loc[info['plots'].index == chart]['plot'].isin(chart_dfs_mlt[chart].Plot.unique().tolist())]\n",
    "    # For each plot\n",
    "    for plot in tqdm(chart_info['plot'].to_list(), desc = \"Creating plots for chart \" + str(chart)):\n",
    "        \n",
    "        plot_info = info['plots'].loc[info['plots'].index == chart].query('plot == \"' + plot + '\"')\n",
    "        plot_fig = go.Figure()\n",
    "        \n",
    "        #Add traces\n",
    "        for par_id in range(0, len(chart_dfs_mlt[chart].query('Plot == \"' + plot + '\"').Parameter.unique())):\n",
    "            par = chart_dfs_mlt[chart].query('Plot == \"' + plot + '\"').Parameter.unique()[par_id]\n",
    "            par_info = plot_pars[chart].query('parameter == \"' + par + '\"')\n",
    "            if len(par_info) != 0:\n",
    "                x_data = chart_dfs_mlt[chart][chart_dfs_mlt[chart].Parameter == par].DateTime\n",
    "                y_data = chart_dfs_mlt[chart][chart_dfs_mlt[chart].Parameter == par].Value\n",
    "                y_error = chart_dfs_mlt[chart][chart_dfs_mlt[chart].Parameter == par].Error\n",
    "\n",
    "                trace_base = go.Scatter(x=x_data, y=y_data,\n",
    "                            name=par_info['parameter_lab'][0], \n",
    "                            legendgroup=par_info['parameter_lab'][0])\n",
    "\n",
    "                if par_info['line'].values == True:\n",
    "                    legend_show = True #default on\n",
    "                    if par_info['show_in_legend'].values == False or par_info['point'].values == True or par_info['bar'].values == True:\n",
    "                        legend_show = False\n",
    "                    trace = trace_base\n",
    "                    trace.update(mode = \"lines\",\n",
    "                                line=dict(color=par_info['colour'][0], width=2, dash=par_info['dash'][0]),\n",
    "                                connectgaps=False,\n",
    "                                showlegend=legend_show)\n",
    "                    plot_fig.add_trace(trace)\n",
    "\n",
    "                if par_info['point'].values == True:\n",
    "                    trace = trace_base\n",
    "                    trace.update(mode = 'markers',\n",
    "                                marker = dict(color = par_info['fill'][0], symbol = par_info['shape'][0],\n",
    "                                            line = dict(color = par_info['colour'][0],width=1)),\n",
    "                                showlegend = bool(par_info['show_in_legend'][0]),\n",
    "                                error_y = dict(type = 'data', array = y_error, visible = True))\n",
    "                    plot_fig.add_trace(trace)\n",
    "\n",
    "                if par_info['ribbon'].values == True:\n",
    "                    ribbon_base = go.Scatter(x=x_data,\n",
    "                                            name=par_info['parameter_lab'][0],\n",
    "                                            line=dict(color=par_info['colour'][0], dash = 'dot'),\n",
    "                                            connectgaps=True,\n",
    "                                            legendgroup=par_info['parameter_lab'][0],\n",
    "                                            showlegend=False,\n",
    "                                            hoverinfo='skip')\n",
    "                    trace1 = ribbon_base\n",
    "                    trace1.update(y=y_data + y_error, mode='lines', line=dict(width=0))\n",
    "                    plot_fig.add_trace(trace1)\n",
    "                    trace2 = ribbon_base\n",
    "                    trace2.update(y=y_data - y_error, fill='tonexty', mode='none', fillcolor=par_info['fill'][0],\n",
    "                                line=dict(width=0.5)) #fill to trace1 y\n",
    "                    plot_fig.add_trace(trace2)\n",
    "\n",
    "        #Modify plot\n",
    "        plot_fig.update_layout(\n",
    "            margin=dict(l=100, r=250, b=15, t=15, pad=10),\n",
    "            template=\"simple_white\",\n",
    "            paper_bgcolor='rgba(0,0,0,0)',\n",
    "            font=dict(\n",
    "                family=\"Arial\",\n",
    "                size=12,\n",
    "                color=\"black\"\n",
    "            ))\n",
    "        plot_fig.update_yaxes(title_text=plot_info['ylab'][chart], mirror=True)\n",
    "        plot_fig.update_xaxes(showgrid=True, showticklabels=False, ticks=\"\",\n",
    "            showline=True, mirror=True,\n",
    "            range=[min(chart_dfs_mlt[chart].DateTime), max(chart_dfs_mlt[chart].DateTime)],\n",
    "            fixedrange=True) #prevent x zoom\n",
    "        \n",
    "        #Special plot mods\n",
    "        if plot_info['log'][chart] == True:\n",
    "            plot_fig.update_layout(yaxis_type=\"log\")\n",
    "            plot_fig.update_yaxes(range=[math.log(plot_info['ymin'][chart], 10), math.log(plot_info['ymax'][chart], 10)])\n",
    "        else:\n",
    "            plot_fig.update_yaxes(range=[plot_info['ymin'][chart], plot_info['ymax'][chart]])\n",
    "\n",
    "        if plot == chart_info['plot'].to_list()[len(chart_info['plot'].to_list())-1]: #Add date to last chart\n",
    "            plot_fig.update_xaxes(showticklabels=True, ticks=\"outside\")\n",
    "\n",
    "        chart_fig[plot] = plot_fig\n",
    "    return(chart_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dash interactive chart figures\n",
    "def create_dash_graphs(chart):\n",
    "    dcc_chart_fig = []\n",
    "    p = 0\n",
    "    for plot in chart_figs[chart]:\n",
    "        if p != len(chart_figs[chart])-1: #if not the last chart\n",
    "            height = '20vh'\n",
    "        else:\n",
    "            height = '25vh'\n",
    "        dcc_chart_fig.append(dcc.Graph(id='graph' + str(p),\n",
    "                                            figure=chart_figs[chart][plot],\n",
    "                                            style={'width': '98vw', 'height': ''+ height + ''}))\n",
    "        p = p + 1\n",
    "    return(dcc_chart_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create offline interactive chart figures\n",
    "def create_offline_graphs(chart):\n",
    "    div_chart_fig = OrderedDict()\n",
    "    p = 0\n",
    "    for plot in chart_figs[chart]:\n",
    "        div_chart_fig[plot] = plotly.offline.plot(chart_figs[chart][plot], include_plotlyjs=False, output_type='div')\n",
    "        div_chart_fig[plot] = div_chart_fig[plot].replace('style=\"height:100%; width:100%;\"',\n",
    "        'style=\"height:20%; width:98%;\"')\n",
    "        if p == len(chart_figs[chart])-1: #if the last chart\n",
    "            div_chart_fig[plot] = div_chart_fig[plot].replace('style=\"height:20%;\"', 'style=\"height:25%;\"')\n",
    "        p = p + 1\n",
    "    return(div_chart_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_folder_contents(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "def check_folder_exists(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "        return(False)\n",
    "    else:\n",
    "        return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_html(chart):\n",
    "    #Build start and end strings\n",
    "    html_string_start = '''\n",
    "    <html>\n",
    "        <head>\n",
    "            <style>body{ margin:0 100; background:white; font-family: Arial, Helvetica, sans-serif}</style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <h1>''' + info['setup'].loc['project','value'] + ''' offline data analysis</h1>\n",
    "            <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "            '''\n",
    "\n",
    "    html_string_end = '''\n",
    "        </body>\n",
    "    </html>'''\n",
    "\n",
    "    #Create html header\n",
    "    html_string = html_string_start\n",
    "\n",
    "    chart_start_date = set_date(info['charts']['chart_range_start'][chart].replace('+00:00',''), \"UTC\")\n",
    "    chart_end_date = set_date(info['charts']['chart_range_end'][chart].replace('+00:00',''), \"UTC\")\n",
    "    html_string = html_string + '''<p>''' + humanize.naturaldate(chart_start_date) + ''' to ''' + humanize.naturaldate(chart_end_date)\n",
    "\n",
    "    resample = info['charts']['chart_res'][chart]\n",
    "    if resample != 0:\n",
    "        html_string = html_string + ''' | Data resampled over ''' + str(resample) + ''' minutes</p>'''\n",
    "    else:\n",
    "        html_string = html_string + '''</p>'''\n",
    "\n",
    "    #Add divs to html string\n",
    "    for plot in chart_figs[chart]:\n",
    "        html_string = html_string + div_chart_figs[chart][plot]\n",
    "\n",
    "    #write finished html\n",
    "    html_string + html_string_end\n",
    "    hreport = open('Output/' + str(chart) + \"_\" + info['charts'].loc[chart, 'chart'] + \".html\",'w')\n",
    "    hreport.write(html_string)\n",
    "    hreport.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_png(chart):\n",
    "    #Export PNGs\n",
    "    if check_folder_exists(\"Temp\"):\n",
    "        if check_folder_exists(\"Temp/PNGs/\"):\n",
    "            delete_folder_contents(\"Temp/PNGs\")\n",
    "\n",
    "    png_folder = \"Temp/PNGs/\" + str(chart) + \"_\" + info['charts'].loc[chart, 'chart'] + \"/\"\n",
    "    os.mkdir(png_folder)\n",
    "\n",
    "    divisor = len(chart_figs[chart])-1 + info['charts']['last_fig_x'][chart]\n",
    "\n",
    "    p = 0\n",
    "    #Export individual pngs\n",
    "    for plot in chart_figs[chart]:\n",
    "        if p != len(chart_figs[chart])-1: #if not the last chart\n",
    "            height = info['charts']['png_height'][chart]/divisor\n",
    "        else:\n",
    "            height = (info['charts']['png_height'][chart]/divisor) * info['charts']['last_fig_x'][chart]\n",
    "        \n",
    "        chart_figs[chart][plot].write_image(png_folder + str(p).zfill(2) + \"_\" + plot + \".png\",\n",
    "                                            width=info['charts']['png_width'][chart],\n",
    "                                            height=height,\n",
    "                                            scale=1)\n",
    "        p = p + 1\n",
    "\n",
    "    images = [Image.open(png_folder + x) for x in os.listdir(png_folder)]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    max_width = max(widths)\n",
    "    total_height = sum(heights)\n",
    "\n",
    "    new_im = Image.new('RGBA', (max_width, total_height))\n",
    "\n",
    "    y_offset = 0\n",
    "    for im in images:\n",
    "        new_im.paste(im, (0,y_offset))\n",
    "        y_offset += im.size[1]\n",
    "\n",
    "    new_im.save(\"Output/\" + str(chart) + \"_\" + info['charts'].loc[chart, 'chart'] + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refresh data in temp folder if older than refresh limit or first run\n",
    "refresh_data()\n",
    "\n",
    "#Import data from temp_files\n",
    "info = import_temp_data(\"info\", \"odict\", index_bool=True)\n",
    "chart_dfs_mlt = import_temp_data(\"chart_dfs_mlt\", \"list\", index_bool=False)\n",
    "plot_pars = import_temp_data(\"plot_pars\", \"list\", index_bool=True)\n",
    "\n",
    "#Create useful shortcuts\n",
    "charts = info['charts'].index.to_list()\n",
    "date_end = set_date(info['setup'].loc['date_end_utc','value'].replace('+00:00',''), \"UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "\n  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\nCreating and exporting plots for chart 0:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n\nCreating plots for chart 0:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n\nCreating plots for chart 0:  10%|█         | 1/10 [00:00<00:05,  1.67it/s]\u001b[A\u001b[A\n\nCreating plots for chart 0:  20%|██        | 2/10 [00:01<00:04,  1.66it/s]\u001b[A\u001b[A\n\nCreating plots for chart 0:  30%|███       | 3/10 [00:01<00:04,  1.66it/s]\u001b[A\u001b[A\n\nCreating plots for chart 0:  40%|████      | 4/10 [00:02<00:03,  1.54it/s]\u001b[A\u001b[A\n\nCreating plots for chart 0:  50%|█████     | 5/10 [00:03<00:03,  1.50it/s]\u001b[A\u001b[A\n\nCreating plots for chart 0:  60%|██████    | 6/10 [00:04<00:03,  1.27it/s]\u001b[A\u001b[A\n\nCreating plots for chart 0:  70%|███████   | 7/10 [00:04<00:02,  1.36it/s]\u001b[A\u001b[A\n\nCreating plots for chart 0:  80%|████████  | 8/10 [00:05<00:01,  1.66it/s]\u001b[A\u001b[A\n\nCreating plots for chart 0:  90%|█████████ | 9/10 [00:05<00:00,  1.95it/s]\u001b[A\u001b[A\n\nCreating plots for chart 0: 100%|██████████| 10/10 [00:06<00:00,  1.47it/s]\n\nCreating and exporting plots for chart 0:  20%|██        | 1/5 [00:11<00:44, 11.09s/it]\u001b[A\nCreating and exporting plots for chart 1:  20%|██        | 1/5 [00:11<00:44, 11.09s/it]\u001b[A\n\nCreating plots for chart 1:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n\nCreating plots for chart 1:  10%|█         | 1/10 [00:00<00:07,  1.15it/s]\u001b[A\u001b[A\n\nCreating plots for chart 1:  20%|██        | 2/10 [00:01<00:06,  1.24it/s]\u001b[A\u001b[A\n\nCreating plots for chart 1:  30%|███       | 3/10 [00:02<00:05,  1.34it/s]\u001b[A\u001b[A\n\nCreating plots for chart 1:  40%|████      | 4/10 [00:02<00:04,  1.33it/s]\u001b[A\u001b[A\n\nCreating plots for chart 1:  50%|█████     | 5/10 [00:03<00:03,  1.37it/s]\u001b[A\u001b[A\n\nCreating plots for chart 1:  60%|██████    | 6/10 [00:03<00:02,  1.61it/s]\u001b[A\u001b[A\n\nCreating plots for chart 1:  70%|███████   | 7/10 [00:04<00:02,  1.41it/s]\u001b[A\u001b[A\n\nCreating plots for chart 1:  80%|████████  | 8/10 [00:05<00:01,  1.70it/s]\u001b[A\u001b[A\n\nCreating plots for chart 1:  90%|█████████ | 9/10 [00:05<00:00,  1.98it/s]\u001b[A\u001b[A\n\nCreating plots for chart 1: 100%|██████████| 10/10 [00:06<00:00,  1.50it/s]\n\nCreating and exporting plots for chart 1:  40%|████      | 2/5 [00:22<00:33, 11.16s/it]\u001b[A\nCreating and exporting plots for chart 2:  40%|████      | 2/5 [00:22<00:33, 11.16s/it]\u001b[A\n\nCreating plots for chart 2:   0%|          | 0/14 [00:00<?, ?it/s]\u001b[A\u001b[A\n\nCreating plots for chart 2:   7%|▋         | 1/14 [00:00<00:08,  1.61it/s]\u001b[A\u001b[A\n\nCreating plots for chart 2:  14%|█▍        | 2/14 [00:01<00:07,  1.58it/s]\u001b[A\u001b[A\n\nCreating plots for chart 2:  21%|██▏       | 3/14 [00:01<00:06,  1.59it/s]\u001b[A\u001b[A\n\nCreating plots for chart 2:  29%|██▊       | 4/14 [00:02<00:05,  1.73it/s]\u001b[A\u001b[A\n\nCreating plots for chart 2:  36%|███▌      | 5/14 [00:02<00:04,  1.91it/s]\u001b[A\u001b[A\n\nCreating plots for chart 2:  43%|████▎     | 6/14 [00:03<00:05,  1.40it/s]\u001b[A\u001b[A\n\nCreating plots for chart 2:  50%|█████     | 7/14 [00:04<00:05,  1.37it/s]\u001b[A\u001b[A\n\nCreating plots for chart 2:  57%|█████▋    | 8/14 [00:05<00:03,  1.62it/s]\u001b[A\u001b[A\n\nCreating plots for chart 2:  64%|██████▍   | 9/14 [00:05<00:02,  1.67it/s]\u001b[A\u001b[A\n\nCreating plots for chart 2:  71%|███████▏  | 10/14 [00:05<00:02,  1.85it/s]\u001b[A\u001b[A\n\nCreating plots for chart 2:  79%|███████▊  | 11/14 [00:06<00:01,  2.13it/s]\u001b[A\u001b[A\n\nCreating plots for chart 2:  86%|████████▌ | 12/14 [00:07<00:01,  1.50it/s]\u001b[A\u001b[A\n\nCreating plots for chart 2:  93%|█████████▎| 13/14 [00:08<00:00,  1.51it/s]\u001b[A\u001b[A\n\nCreating plots for chart 2: 100%|██████████| 14/14 [00:08<00:00,  1.66it/s]\n\nCreating and exporting plots for chart 2:  60%|██████    | 3/5 [00:35<00:23, 11.89s/it]\u001b[A\nCreating and exporting plots for chart 3:  60%|██████    | 3/5 [00:35<00:23, 11.89s/it]\u001b[A\n\nCreating plots for chart 3:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\u001b[A\n\nCreating plots for chart 3:   8%|▊         | 1/12 [00:01<00:12,  1.14s/it]\u001b[A\u001b[A\n\nCreating plots for chart 3:  17%|█▋        | 2/12 [00:01<00:09,  1.09it/s]\u001b[A\u001b[A\n\nCreating plots for chart 3:  25%|██▌       | 3/12 [00:01<00:06,  1.34it/s]\u001b[A\u001b[A\n\nCreating plots for chart 3:  33%|███▎      | 4/12 [00:02<00:05,  1.37it/s]\u001b[A\u001b[A\n\nCreating plots for chart 3:  42%|████▏     | 5/12 [00:03<00:04,  1.53it/s]\u001b[A\u001b[A\n\nCreating plots for chart 3:  50%|█████     | 6/12 [00:03<00:03,  1.78it/s]\u001b[A\u001b[A\n\nCreating plots for chart 3:  58%|█████▊    | 7/12 [00:03<00:02,  1.86it/s]\u001b[A\u001b[A\n\nCreating plots for chart 3:  67%|██████▋   | 8/12 [00:04<00:02,  1.98it/s]\u001b[A\u001b[A\n\nCreating plots for chart 3:  75%|███████▌  | 9/12 [00:04<00:01,  2.26it/s]\u001b[A\u001b[A\n\nCreating plots for chart 3:  83%|████████▎ | 10/12 [00:05<00:01,  1.52it/s]\u001b[A\u001b[A\n\nCreating plots for chart 3:  92%|█████████▏| 11/12 [00:06<00:00,  1.83it/s]\u001b[A\u001b[A\n\nCreating plots for chart 3: 100%|██████████| 12/12 [00:06<00:00,  1.87it/s]\n\nCreating and exporting plots for chart 3:  80%|████████  | 4/5 [00:47<00:11, 11.72s/it]\u001b[A\nCreating and exporting plots for chart 4: 100%|██████████| 5/5 [00:47<00:00,  9.46s/it]\n"
    }
   ],
   "source": [
    "#Create chart figures for plotly, dash and offline interactive\n",
    "chart_figs = []\n",
    "dcc_chart_figs = []\n",
    "div_chart_figs = []\n",
    "pbar = tqdm(charts)\n",
    "for chart in pbar:\n",
    "    pbar.set_description(\"Creating and exporting plots for chart %s\" % chart)\n",
    "    if info['charts'].loc[chart, 'chart_status'] == 'ON':\n",
    "        chart_figs.append(create_chart_fig(chart))\n",
    "        div_chart_figs.append(create_offline_graphs(chart))\n",
    "        export_html(chart)\n",
    "        export_png(chart)\n",
    "        dcc_chart_figs.append(create_dash_graphs(chart))\n",
    "    else:\n",
    "        chart_figs.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "divisor = len(chart_figs[chart])-1 + info['charts']['last_fig_x'][chart]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = 0\n",
    "\n",
    "#Export PDFs and PNGs\n",
    "if check_folder_exists(\"Temp\"):\n",
    "    if check_folder_exists(\"Temp/PDFs/\"):\n",
    "        delete_folder_contents(\"Temp/PDFs\")\n",
    "    if check_folder_exists(\"Temp/PNGs/\"):\n",
    "        delete_folder_contents(\"Temp/PNGs\")\n",
    "\n",
    "pdf_folder = \"Temp/PDFs/\" + str(chart) + \"_\" + info['charts'].loc[chart, 'chart'] + \"/\"\n",
    "os.mkdir(pdf_folder)\n",
    "png_folder = \"Temp/PNGs/\" + str(chart) + \"_\" + info['charts'].loc[chart, 'chart'] + \"/\"\n",
    "os.mkdir(png_folder)\n",
    "\n",
    "divisor = len(chart_figs[chart])-1 + info['charts']['last_fig_x'][chart]\n",
    "\n",
    "p = 0\n",
    "#Export individual pdfs and pngs\n",
    "for plot in chart_figs[chart]:\n",
    "    if p != len(chart_figs[chart])-1: #if not the last chart\n",
    "        height = info['charts']['pdf_height'][chart]/divisor\n",
    "    else:\n",
    "        height = (info['charts']['pdf_height'][chart]/divisor) * info['charts']['last_fig_x'][chart]\n",
    "    chart_figs[chart][plot].write_image(pdf_folder + str(p).zfill(2) + \"_\" + plot + \".pdf\",\n",
    "                                        width=info['charts']['pdf_width'][chart],\n",
    "                                        height=height,\n",
    "                                        scale=1)\n",
    "    chart_figs[chart][plot].write_image(png_folder + str(p).zfill(2) + \"_\" + plot + \".png\",\n",
    "                                        width=info['charts']['png_width'][chart],\n",
    "                                        height=height,\n",
    "                                        scale=1)\n",
    "    p = p + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(pdf_dir, output_pdf):\n",
    "    merger = PdfFileMerger(strict=False)\n",
    "\n",
    "    for filename in os.listdir(pdf_dir):\n",
    "        merger.append(PdfFileReader(pdf_dir + filename, strict=False))\n",
    "\n",
    "    with open(output_pdf, 'wb') as fh:\n",
    "        merger.write(fh)\n",
    "        \n",
    "#Export PDFs and PNGs\n",
    "if check_folder_exists(\"Temp\"):\n",
    "    if check_folder_exists(\"Temp/PDFs/\"):\n",
    "        delete_folder_contents(\"Temp/PDFs\")\n",
    "    if check_folder_exists(\"Temp/PNGs/\"):\n",
    "        delete_folder_contents(\"Temp/PNGs\")\n",
    "\n",
    "pdf_folder = \"Temp/PDFs/\" + str(chart) + \"_\" + info['charts'].loc[chart, 'chart'] + \"/\"\n",
    "os.mkdir(pdf_folder)\n",
    "png_folder = \"Temp/PNGs/\" + str(chart) + \"_\" + info['charts'].loc[chart, 'chart'] + \"/\"\n",
    "os.mkdir(png_folder)\n",
    "\n",
    "p = 0\n",
    "#Export individual pdfs and pngs\n",
    "for plot in chart_figs[chart]:\n",
    "    chart_figs[chart][plot].write_image(pdf_folder + str(p).zfill(2) + \"_\" + plot + \".pdf\", width=210*6, height=29.7*6, scale=1)\n",
    "    chart_figs[chart][plot].write_image(png_folder + str(p).zfill(2) + \"_\" + plot + \".pdf\", width=210*6, height=29.7*6, scale=1)\n",
    "    p = p + 1\n",
    "\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "images = [Image.open(png_folder + x) for x in os.listdir(png_folder)]\n",
    "widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "total_width = sum(widths)\n",
    "max_height = max(heights)\n",
    "\n",
    "new_im = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "x_offset = 0\n",
    "for im in images:\n",
    "  new_im.paste(im, (x_offset,0))\n",
    "  x_offset += im.size[0]\n",
    "\n",
    "new_im.save('test.jpg')\n",
    "\n",
    "\n",
    "\n",
    "#write finished html\n",
    "html_strings[chart] + html_string_end\n",
    "hreport = open('Output/' + str(chart) + \"_\" + info['charts'].loc[chart, 'chart'] + \".html\",'w')\n",
    "hreport.write(html_strings[chart])\n",
    "hreport.close()\n",
    "\n",
    "#Combine pdfs\n",
    "if __name__ == '__main__':\n",
    "    combine(pdf_dir=folder, \n",
    "            output_pdf=folder + \"all_pages.pdf\")\n",
    "\n",
    "#Create combined pdf on one page\n",
    "with open(folder + 'all_pages.pdf', 'rb') as input_file:\n",
    "    # load input pdf\n",
    "    input_pdf = PdfFileReader(input_file)\n",
    "    num_pages = input_pdf.getNumPages()\n",
    "    output_pdf = input_pdf.getPage(num_pages-1)\n",
    "\n",
    "    for p in tqdm(reversed(range(0,num_pages-1)), desc=\"Combining plots into one pdf:\"):\n",
    "        second_pdf = input_pdf.getPage(p)\n",
    "        # dimensions for offset from loaded page (adding it to the top)\n",
    "        offset_x = 0 # use for x offset -> output_pdf.mediaBox[2]\n",
    "        offset_y = output_pdf.mediaBox[3]\n",
    "        #merge pdf pages\n",
    "        output_pdf.mergeTranslatedPage(second_pdf, offset_x, offset_y, expand=True)\n",
    "\n",
    "    # write finished pdf\n",
    "    output_file = \"Output/\" + str(chart) + \"_\" + info['charts'].loc[chart, 'chart'] + \".pdf\"\n",
    "    with open(output_file, 'wb') as out_file:\n",
    "            write_pdf = PdfFileWriter()\n",
    "            write_pdf.addPage(output_pdf)\n",
    "            write_pdf.write(out_file)\n",
    "\n",
    "#Convert pdf to png \n",
    "inp = PdfFileReader(output_file, \"rb\")\n",
    "page = inp.getPage(0)\n",
    "wrt = PdfFileWriter()\n",
    "wrt.addPage(page)\n",
    "\n",
    "r = io.BytesIO()\n",
    "wrt.write(r)\n",
    "images = convert_from_bytes(r.getvalue())\n",
    "images[0].save(output_file[:-4]+\".png\")\n",
    "\n",
    "#Delete temp pdfs\n",
    "try:\n",
    "    shutil.rmtree(folder)\n",
    "except OSError as e:\n",
    "    print (\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export HTML, PDFs and PNGs\n",
    "if check_folder_exists(\"Temp\"):\n",
    "    if check_folder_exists(\"Temp/PDFs/\"):\n",
    "        delete_folder_contents(\"Temp/PDFs\")\n",
    "\n",
    "html_strings = []\n",
    "for chart in tqdm(charts, desc=\"Exporting PDFs\"):\n",
    "    if info['charts'].loc[chart, 'chart_status'] == 'ON':\n",
    "        folder = \"Temp/PDFs/\" + str(chart) + \"_\" + info['charts'].loc[chart, 'chart'] + \"/\"\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "        else:\n",
    "            delete_folder_contents(folder)\n",
    "        p = 0\n",
    "\n",
    "        #Create html header\n",
    "        html_strings.append(html_string_start)\n",
    "        start = set_date(info['charts']['chart_range_start'][chart].replace('+00:00',''), \"UTC\")\n",
    "        end = set_date(info['charts']['chart_range_end'][chart].replace('+00:00',''), \"UTC\")\n",
    "        resample = info['charts']['chart_res'][chart]\n",
    "        html_strings[chart] = html_strings[chart] + '''<p>''' + humanize.naturaldate(start) + ''' to ''' + humanize.naturaldate(end) \n",
    "        if resample != 0:\n",
    "            html_strings[chart] = html_strings[chart] + ''' | Data resampled over ''' + str(resample) + ''' minutes</p>'''\n",
    "        else:\n",
    "            html_strings[chart] = html_strings[chart] + '''</p>'''\n",
    "        \n",
    "        #Export individual pdfs and divs\n",
    "        for plot in chart_figs[chart]:\n",
    "            chart_figs[chart][plot].write_image(folder + str(p).zfill(2) + \"_\" + plot + \".pdf\", width=210*6, height=29.7*6, scale=1)\n",
    "            html_strings[chart] = html_strings[chart] + div_chart_figs[chart][plot]\n",
    "            p = p + 1\n",
    "        \n",
    "        #write finished html\n",
    "        html_strings[chart] + html_string_end\n",
    "        hreport = open('Output/' + str(chart) + \"_\" + info['charts'].loc[chart, 'chart'] + \".html\",'w')\n",
    "        hreport.write(html_strings[chart])\n",
    "        hreport.close()\n",
    "\n",
    "        #Combine pdfs\n",
    "        if __name__ == '__main__':\n",
    "            combine(pdf_dir=folder, \n",
    "                    output_pdf=folder + \"all_pages.pdf\")\n",
    "        \n",
    "        #Create combined pdf on one page\n",
    "        with open(folder + 'all_pages.pdf', 'rb') as input_file:\n",
    "            # load input pdf\n",
    "            input_pdf = PdfFileReader(input_file)\n",
    "            num_pages = input_pdf.getNumPages()\n",
    "            output_pdf = input_pdf.getPage(num_pages-1)\n",
    "\n",
    "            for p in tqdm(reversed(range(0,num_pages-1)), desc=\"Combining plots into one pdf:\"):\n",
    "                second_pdf = input_pdf.getPage(p)\n",
    "                # dimensions for offset from loaded page (adding it to the top)\n",
    "                offset_x = 0 # use for x offset -> output_pdf.mediaBox[2]\n",
    "                offset_y = output_pdf.mediaBox[3]\n",
    "                #merge pdf pages\n",
    "                output_pdf.mergeTranslatedPage(second_pdf, offset_x, offset_y, expand=True)\n",
    "\n",
    "            # write finished pdf\n",
    "            output_file = \"Output/\" + str(chart) + \"_\" + info['charts'].loc[chart, 'chart'] + \".pdf\"\n",
    "            with open(output_file, 'wb') as out_file:\n",
    "                    write_pdf = PdfFileWriter()\n",
    "                    write_pdf.addPage(output_pdf)\n",
    "                    write_pdf.write(out_file)\n",
    "\n",
    "        #Convert pdf to png \n",
    "        inp = PdfFileReader(output_file, \"rb\")\n",
    "        page = inp.getPage(0)\n",
    "        wrt = PdfFileWriter()\n",
    "        wrt.addPage(page)\n",
    "\n",
    "        r = io.BytesIO()\n",
    "        wrt.write(r)\n",
    "        images = convert_from_bytes(r.getvalue())\n",
    "        images[0].save(output_file[:-4]+\".png\")\n",
    "        \n",
    "        #Delete temp pdfs\n",
    "        try:\n",
    "            shutil.rmtree(folder)\n",
    "        except OSError as e:\n",
    "            print (\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "    else:\n",
    "        html_strings.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dash app\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "#external_stylesheets = [dbc.themes.LITERA]\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets = external_stylesheets)\n",
    "\n",
    "tabs_init = []\n",
    "for chart in charts:\n",
    "    if info['charts'].loc[chart, 'chart_status'] == 'ON':\n",
    "        tabs_init.append(dcc.Tab(label=info['charts']['chart_label'][chart], value=\"\".join([\"tab-\", str(chart)])))\n",
    "\n",
    "diff = datetime.now(timezone('UTC')) - date_end\n",
    "last_date = humanize.naturaldelta(diff)\n",
    "update_text = html.Div(html.P('Data last retrieved ' + last_date + ' ago'))\n",
    "\n",
    "app.layout = html.Div(children=[\n",
    "    html.Div([html.Img(src=app.get_asset_url('ToOL-PRO-BES.png'), style={'width':'90%', 'max-width': '100%'})], style={'textAlign': 'center'}),\n",
    "    update_text,\n",
    "    html.Div(children=[\n",
    "        dcc.Tabs(id=\"tabs\",\n",
    "            value=\"tab-0\",\n",
    "            children=tabs_init),\n",
    "\n",
    "        html.Div(children=[\n",
    "            dcc.Loading(id='tabs-content')\n",
    "        ]),\n",
    "    ]),\n",
    "])\n",
    "\n",
    "@app.callback(Output('tabs-content', 'children'),\n",
    "              [Input('tabs', 'value')])\n",
    "def render_content(tab):\n",
    "    time.sleep(2)\n",
    "    if tab == 'tab-0':\n",
    "        return html.Div(id='loading-0', children=dcc_chart_figs[0])\n",
    "    elif tab == 'tab-1':\n",
    "        return html.Div(id='loading-1', children=dcc_chart_figs[1])\n",
    "    elif tab == 'tab-2':\n",
    "        return html.Div(id='loading-2', children=dcc_chart_figs[2])\n",
    "    elif tab == 'tab-3':\n",
    "        return html.Div(id='loading-3', children=dcc_chart_figs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run_server()\n",
    "    #debug=True, dev_tools_hot_reload_interval=5000)\n",
    "                   #dev_tools_hot_reload_max_retry=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab1_content = dbc.Card(\n",
    "    dbc.CardBody(\n",
    "        [\n",
    "            html.P(\"This is tab 1!\", className=\"card-text\"),\n",
    "            dbc.Button(\"Click here\", color=\"success\"),\n",
    "        ]\n",
    "    ),\n",
    "    className=\"mt-3\",\n",
    ")\n",
    "\n",
    "tab2_content = dbc.Card(\n",
    "    dbc.CardBody(\n",
    "        [\n",
    "            html.P(\"This is tab 2!\", className=\"card-text\"),\n",
    "            dbc.Button(\"Don't click here\", color=\"danger\"),\n",
    "        ]\n",
    "    ),\n",
    "    className=\"mt-3\",\n",
    ")\n",
    "\n",
    "\n",
    "tabs = dbc.Tabs(\n",
    "    [\n",
    "        dbc.Tab(tab1_content, label=\"Tab 1\"),\n",
    "        dbc.Tab(tab2_content, label=\"Tab 2\"),\n",
    "        dbc.Tab(\n",
    "            \"This tab's content is never seen\", label=\"Tab 3\", disabled=True\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "layout = html.Div([tabs])\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.LITERA]\n",
    "\n",
    "app.layout = layout"
   ]
  }
 ]
}