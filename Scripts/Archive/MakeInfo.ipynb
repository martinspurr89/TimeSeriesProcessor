{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nms198\\OneDrive - Newcastle University\\3_Coding\\Git\\ToOLTuBESv3\\Scripts\\ProcessData.py:6: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import ProcessData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupIOFolder(folder):\n",
    "    scripts_dir = folder / \"Scripts\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "        print(\"Created Project folder: folder.name\")\n",
    "    else: print(\"Using already existing Project folder (\" + folder.name + \")\")\n",
    "    if not os.path.exists(scripts_dir):\n",
    "        os.mkdir(scripts_dir)\n",
    "        print(\"Created Scripts folder\")\n",
    "    else: print(\"Using already existing Scripts folder\")\n",
    "    sys.path.append(str(scripts_dir))\n",
    "    \n",
    "    cdi_path = scripts_dir / \"CustomDataImports.py\"\n",
    "    if not os.path.exists(cdi_path):\n",
    "        with open(cdi_path, 'w') as f:\n",
    "            f.write('''\\\n",
    "from config import *\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "config['filetypes'] = ['xls', 'csv', 'txt']\n",
    "def fileImport(dataset, folder, filename, pat):\n",
    "    data_folder_path = Path(config['info']['datasets'].query('dataset == \"' + dataset + '\" & folder == \"' + str(folder) + '\"')['data_folder_path'][dataset])\n",
    "    skiprows = config['info']['datasets'].query('dataset == \"' + dataset + '\" & folder == \"' + str(folder) + '\"')['skiprows'][dataset]\n",
    "    if pat == config['filetypes'][0]:\n",
    "        df = pd.read_excel(data_folder_path / filename, skiprows=skiprows)\n",
    "    elif pat == config['filetypes'][1]:\n",
    "        df = pd.read_csv(data_folder_path / filename, skiprows=skiprows)\n",
    "    elif pat == config['filetypes'][2]:\n",
    "        df = pd.read_csv(data_folder_path / filename, sep=\"\\t\", skiprows=skiprows)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown file type!\")\n",
    "    return df\n",
    "\n",
    "### Insert pre-import functions here: names as -> get_DATASET_support_data()\n",
    "\n",
    "###\n",
    "\n",
    "# Set pre-import functions inside dictionary separated by commas as -> 'DATASET': get_DATASET_support_data\n",
    "\n",
    "preimport_functions = {}\n",
    "\n",
    "### Insert data import functions here: names as -> mod_imported_DATASET_data()\n",
    "\n",
    "###\n",
    "\n",
    "# Set data import functions inside dictionary separated by commas as -> 'DATASET': mod_imported_DATASET_data\n",
    "\n",
    "import_functions = {}                 \n",
    "''')\n",
    "        print(\"Created CustomDataImports script placeholder\")\n",
    "    else: print(\"Using already existing CustomDataImports script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set analysis folder and project name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C:\\Users\\nms198\\OneDrive - Newcastle University\\3_Coding\\Python\n",
    "\n",
    "Rod BES BEWISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using already existing Project folder (Rod_BES_BEWISE)\n",
      "Using already existing Scripts folder\n",
      "Using already existing CustomDataImports script\n"
     ]
    }
   ],
   "source": [
    "setup_dict = {}\n",
    "\n",
    "#path = Path(input(\"Enter the path to create your analysis folder in: \"))\n",
    "path = Path(\"C:\\\\Users\\\\nms198\\\\OneDrive - Newcastle University\\\\3_Coding\\\\Python\")\n",
    "#setup_dict['project'] = input(\"Enter the name of this project: \")\n",
    "setup_dict['project'] = \"Rod BES BEWISE\"\n",
    "folder = path / setup_dict['project'].replace(\" \", \"_\")\n",
    "setupIOFolder(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01/12/2017 13:15:00\n",
    "\n",
    "14/01/2019 10:27:00\n",
    "\n",
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup_dict['date_start_utc'] = ProcessData.setUTCDatetime(input(\"Enter the START datetime in UTC timezone (format dd/mm/yyyy  hh:mm:ss): \"), \"UTC\")\n",
    "#setup_dict['date_end_utc'] = ProcessData.setUTCDatetime(input(\"Enter the END datetime in UTC timezone (format dd/mm/yyyy  hh:mm:ss) [leave blank if ongoing experiment]: \"), \"UTC\")\n",
    "#setup_dict['refresh_hours'] = int(input(\"Enter after how many hours data should be refreshed when processing data: \"))\n",
    "\n",
    "setup_dict['date_start_utc'] = ProcessData.setUTCDatetime(\"01/12/2017 13:15:00\", \"UTC\")\n",
    "setup_dict['date_end_utc'] = ProcessData.setUTCDatetime(\"14/01/2019 10:27:00\", \"UTC\")\n",
    "setup_dict['refresh_hours'] = int(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_df = pd.DataFrame(setup_dict.items(), columns = ['id','value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>project</td>\n",
       "      <td>Rod BES BEWISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>date_start_utc</td>\n",
       "      <td>2017-12-01 13:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>date_end_utc</td>\n",
       "      <td>2019-01-14 10:27:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>refresh_hours</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                value\n",
       "0         project       Rod BES BEWISE\n",
       "1  date_start_utc  2017-12-01 13:15:00\n",
       "2    date_end_utc  2019-01-14 10:27:00\n",
       "3   refresh_hours                    4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for row in range(0,len(setup_df)):\n",
    "    if isinstance(setup_df.loc[row,'value'], datetime):\n",
    "        setup_df.loc[row,'value'] = setup_df.loc[row,'value'].replace(tzinfo=None)\n",
    "setup_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(folder / 'Info_test.xlsx',\n",
    "                        engine = 'xlsxwriter',\n",
    "                        datetime_format = 'dd/mm/yyyy  hh:mm:ss') as writer:\n",
    "    setup_df.to_excel(writer, sheet_name='setup', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/nms198/OneDrive - Newcastle University/3_Coding/Python/Rod_BES_BEWISE/Info_test.xlsx')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\tfolder\tselection\tmelt\tdata_folder_path\tsupp_data_filepath\tfile_pat\tskiprows\tSlim\tDel_unit_rows\tAdd_blank_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of dataset folders to import:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>folder</th>\n",
       "      <th>selection</th>\n",
       "      <th>melt</th>\n",
       "      <th>data_folder_path</th>\n",
       "      <th>supp_data_filepath</th>\n",
       "      <th>file_pat</th>\n",
       "      <th>skiprows</th>\n",
       "      <th>Slim</th>\n",
       "      <th>Del_unit_rows</th>\n",
       "      <th>Add_blank_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dataset, folder, selection, melt, data_folder_path, supp_data_filepath, file_pat, skiprows, Slim, Del_unit_rows, Add_blank_rows]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"dataset\", \"folder\", \"selection\", \"melt\", \"data_folder_path\", \"supp_data_filepath\", \"file_pat\", \"skiprows\", \"Slim\", \"Del_unit_rows\", \"Add_blank_rows\"])\n",
    "parts = int(input(\"Enter the number of dataset folders to import:\"))\n",
    "\n",
    "for _ in range(parts):\n",
    "    dataset = input(\"Enter DATASET name:\")\n",
    "    folder = int(input(dataset + \": Enter FOLDER number:\"))\n",
    "    selection = input(dataset + \": Enter SELECTION name:\")\n",
    "    melt = input(dataset + \": Enter MELT name:\")\n",
    "    data_folder_path = Path(input(dataset + \": Enter DATA FOLDER PATH name:\"))\n",
    "    supp_data_filepath = Path(input(dataset + \": Enter SUPPORTING DATA FILEPATH name:\"))\n",
    "    file_pat = input(dataset + \": Enter FILE PATTERN as .***:\")\n",
    "    skiprows = input(dataset + \": Enter number of top rows to SKIP in datafile:\")\n",
    "    Slim = input(dataset + \": Enter 1 for SLIM or leave blank for wide datafile:\")\n",
    "    Del_unit_rows = input(dataset + \": Enter 1 to DELETE UNIT ROWS after headers or leave blank for no unit deletion in datafile:\")\n",
    "    Add_blank_rows = input(dataset + \": Enter 1 to ADD BLANK ROWS after datafile or leave blank for continuous data:\")\n",
    "    \n",
    "    df1 = pd.DataFrame(data=[[dataset,folder,selection,melt,data_folder_path,supp_data_filepath,file_pat,skiprows,Slim,Del_unit_rows,Add_blank_rows]],\n",
    "                       columns=[\"dataset\", \"folder\", \"selection\", \"melt\", \"data_folder_path\", \"supp_data_filepath\", \"file_pat\", \"skiprows\", \"Slim\", \"Del_unit_rows\", \"Add_blank_rows\"])\n",
    "    df = pd.concat([df,df1], axis=0)\n",
    "\n",
    "df.index = range(len(df.index))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDataset(df):\n",
    "    dataset = input(\"Enter DATASET name:\")\n",
    "    folder = int(input(dataset + \": Enter FOLDER number:\"))\n",
    "    selection = input(dataset + \": Enter SELECTION name:\")\n",
    "    melt = input(dataset + \": Enter MELT name:\")\n",
    "    data_folder_path = Path(input(dataset + \": Enter DATA FOLDER PATH name:\"))\n",
    "    supp_data_filepath = Path(input(dataset + \": Enter SUPPORTING DATA FILEPATH name:\"))\n",
    "    file_pat = input(dataset + \": Enter FILE PATTERN as .***:\")\n",
    "    skiprows = input(dataset + \": Enter number of top rows to SKIP in datafile:\")\n",
    "    Slim = input(dataset + \": Enter 1 for SLIM or leave blank for wide datafile:\")\n",
    "    Del_unit_rows = input(dataset + \": Enter 1 to DELETE UNIT ROWS after headers or leave blank for no unit deletion in datafile:\")\n",
    "    Add_blank_rows = input(dataset + \": Enter 1 to ADD BLANK ROWS after datafile or leave blank for continuous data:\")\n",
    "    \n",
    "    df1 = pd.DataFrame(data=[[dataset,folder,selection,melt,data_folder_path,supp_data_filepath,file_pat,skiprows,Slim,Del_unit_rows,Add_blank_rows]],\n",
    "                       columns=[\"dataset\", \"folder\", \"selection\", \"melt\", \"data_folder_path\", \"supp_data_filepath\", \"file_pat\", \"skiprows\", \"Slim\", \"Del_unit_rows\", \"Add_blank_rows\"])\n",
    "    df = pd.concat([df,df1], axis=0)\n",
    "    df.index = range(len(df.index))\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"dataset\", \"folder\", \"selection\", \"melt\", \"data_folder_path\", \"supp_data_filepath\", \"file_pat\", \"skiprows\", \"Slim\", \"Del_unit_rows\", \"Add_blank_rows\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter DATASET name:abc\n",
      "abc: Enter FOLDER number:1\n",
      "abc: Enter SELECTION name:1\n",
      "abc: Enter MELT name:1\n",
      "abc: Enter DATA FOLDER PATH name:1\n",
      "abc: Enter SUPPORTING DATA FILEPATH name:1\n",
      "abc: Enter FILE PATTERN as .***:1\n",
      "abc: Enter number of top rows to SKIP in datafile:1\n",
      "abc: Enter 1 for SLIM or leave blank for wide datafile:1\n",
      "abc: Enter 1 to DELETE UNIT ROWS after headers or leave blank for no unit deletion in datafile:1\n",
      "abc: Enter 1 to ADD BLANK ROWS after datafile or leave blank for continuous data:1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>folder</th>\n",
       "      <th>selection</th>\n",
       "      <th>melt</th>\n",
       "      <th>data_folder_path</th>\n",
       "      <th>supp_data_filepath</th>\n",
       "      <th>file_pat</th>\n",
       "      <th>skiprows</th>\n",
       "      <th>Slim</th>\n",
       "      <th>Del_unit_rows</th>\n",
       "      <th>Add_blank_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abc</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abc</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset folder selection melt data_folder_path supp_data_filepath file_pat  \\\n",
       "0     abc      1         1    1                1                  1        1   \n",
       "1     abc      1         1    1                1                  1        1   \n",
       "\n",
       "  skiprows Slim Del_unit_rows Add_blank_rows  \n",
       "0        1    1             1              1  \n",
       "1        1    1             1              1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = addDataset(df)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
